{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to C:\\Users\\Dr\n",
      "[nltk_data]     Diban\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to C:\\Users\\Dr\n",
      "[nltk_data]     Diban\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\Dr\n",
      "[nltk_data]     Diban\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\Dr\n",
      "[nltk_data]     Diban\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Dr Diban\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import tweepy\n",
    "import sklearn\n",
    "import xlrd\n",
    "from requests import Request, Session\n",
    "import webbrowser\n",
    "import re\n",
    "import csv\n",
    "import pandas as pd\n",
    "import regex\n",
    "import emoji\n",
    "import nltk\n",
    "from nltk import FreqDist\n",
    "nltk.download('words')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_excel (r'C:\\Users\\Dr Diban\\Desktop\\Fans_data.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time &amp; date</th>\n",
       "      <th>tweets</th>\n",
       "      <th>user</th>\n",
       "      <th>followers</th>\n",
       "      <th>likes</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-11-18 13:32:01</td>\n",
       "      <td>b\"@DuMaMayBe Hmmmm, Me I love Pogba ooh. We'll...</td>\n",
       "      <td>b'Lyrndah'</td>\n",
       "      <td>4070</td>\n",
       "      <td>11797</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-11-18 13:31:49</td>\n",
       "      <td>b\"@Alex_Sportsfan I think the views around Pog...</td>\n",
       "      <td>b'NeeksQuamina'</td>\n",
       "      <td>2908</td>\n",
       "      <td>54666</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-11-18 13:31:45</td>\n",
       "      <td>b'@TrollFootball Doing a better job than pogba...</td>\n",
       "      <td>b'josehgithuthwa'</td>\n",
       "      <td>20</td>\n",
       "      <td>53</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-11-18 13:30:54</td>\n",
       "      <td>b'@utdarena @Reddevi44483856 one thing i have ...</td>\n",
       "      <td>b'cyruskiptoo1Je1'</td>\n",
       "      <td>15</td>\n",
       "      <td>5200</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-11-18 13:30:20</td>\n",
       "      <td>b\"@NeeksQuamina Lol i didn't mean you said som...</td>\n",
       "      <td>b'Alex_Sportsfan'</td>\n",
       "      <td>115</td>\n",
       "      <td>254</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>2020-11-13 13:15:03</td>\n",
       "      <td>b'Man Utd star Bruno Fernandes reveals surpris...</td>\n",
       "      <td>b'manutdnewsonly'</td>\n",
       "      <td>28309</td>\n",
       "      <td>37</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>2020-11-13 13:13:45</td>\n",
       "      <td>b'@LeeMcQueen Eriksen at his best of course I ...</td>\n",
       "      <td>b'johncoxk9'</td>\n",
       "      <td>30</td>\n",
       "      <td>107</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>2020-11-13 13:11:26</td>\n",
       "      <td>b'@eukoalinha @Johnlennondeso2 @leandrocostab_...</td>\n",
       "      <td>b'vin_i1'</td>\n",
       "      <td>203</td>\n",
       "      <td>23010</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>2020-11-13 13:07:12</td>\n",
       "      <td>b'Bruno Fernandes stars in latest UTD Podcast ...</td>\n",
       "      <td>b'unitedtony99'</td>\n",
       "      <td>422</td>\n",
       "      <td>325</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>2020-11-13 13:06:17</td>\n",
       "      <td>b'@JoeWestTowle @DredUtd @hen_barris @CianLUHJ...</td>\n",
       "      <td>b'UtdSub'</td>\n",
       "      <td>105</td>\n",
       "      <td>36691</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             time & date                                             tweets  \\\n",
       "0    2020-11-18 13:32:01  b\"@DuMaMayBe Hmmmm, Me I love Pogba ooh. We'll...   \n",
       "1    2020-11-18 13:31:49  b\"@Alex_Sportsfan I think the views around Pog...   \n",
       "2    2020-11-18 13:31:45  b'@TrollFootball Doing a better job than pogba...   \n",
       "3    2020-11-18 13:30:54  b'@utdarena @Reddevi44483856 one thing i have ...   \n",
       "4    2020-11-18 13:30:20  b\"@NeeksQuamina Lol i didn't mean you said som...   \n",
       "...                  ...                                                ...   \n",
       "2995 2020-11-13 13:15:03  b'Man Utd star Bruno Fernandes reveals surpris...   \n",
       "2996 2020-11-13 13:13:45  b'@LeeMcQueen Eriksen at his best of course I ...   \n",
       "2997 2020-11-13 13:11:26  b'@eukoalinha @Johnlennondeso2 @leandrocostab_...   \n",
       "2998 2020-11-13 13:07:12  b'Bruno Fernandes stars in latest UTD Podcast ...   \n",
       "2999 2020-11-13 13:06:17  b'@JoeWestTowle @DredUtd @hen_barris @CianLUHJ...   \n",
       "\n",
       "                    user  followers  likes  Sentiment  \n",
       "0             b'Lyrndah'       4070  11797        1.0  \n",
       "1        b'NeeksQuamina'       2908  54666       -1.0  \n",
       "2      b'josehgithuthwa'         20     53       -1.0  \n",
       "3     b'cyruskiptoo1Je1'         15   5200       -1.0  \n",
       "4      b'Alex_Sportsfan'        115    254        0.0  \n",
       "...                  ...        ...    ...        ...  \n",
       "2995   b'manutdnewsonly'      28309     37        0.0  \n",
       "2996        b'johncoxk9'         30    107        1.0  \n",
       "2997           b'vin_i1'        203  23010        1.0  \n",
       "2998     b'unitedtony99'        422    325        0.0  \n",
       "2999           b'UtdSub'        105  36691       -1.0  \n",
       "\n",
       "[3000 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove @user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clean_tweets']=df['tweets'].apply(lambda x: re.sub(r\"@[\\w]*[ :]\",'',x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove website link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clean_tweets']=df['clean_tweets'].apply(lambda x:re.sub('(https?:|www)+[\\w./]*', '', x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "de-emojize emotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clean_tweets']=df['clean_tweets'].apply(lambda x:emoji.demojize(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove '_' between words after de-emojize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clean_tweets']=df['clean_tweets'].apply(lambda x:re.sub('_',' ',x))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove any empty tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['clean_tweets']!='']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop_duplicates(subset=['clean_tweets'], keep=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(df['clean_tweets'],df['Sentiment'],random_state=0,test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vect=CountVectorizer().fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['08',\n",
       " '4th',\n",
       " 'added',\n",
       " 'amount',\n",
       " 'ass',\n",
       " 'based',\n",
       " 'blinded',\n",
       " 'buh',\n",
       " 'cdm',\n",
       " 'co',\n",
       " 'controversial',\n",
       " 'curtailing',\n",
       " 'demb',\n",
       " 'dive',\n",
       " 'edges',\n",
       " 'everywhere',\n",
       " 'fault',\n",
       " 'florentin',\n",
       " 'funnily',\n",
       " 'golden',\n",
       " 'happy',\n",
       " 'holiday',\n",
       " 'incision',\n",
       " 'isco',\n",
       " 'kicks',\n",
       " 'leaking',\n",
       " 'looked',\n",
       " 'marcar',\n",
       " 'messi',\n",
       " 'move',\n",
       " 'niggas',\n",
       " 'onuachu',\n",
       " 'partnership',\n",
       " 'pin',\n",
       " 'prefect',\n",
       " 'putting',\n",
       " 'reddevils',\n",
       " 'revolve',\n",
       " 'sat',\n",
       " 'sesh',\n",
       " 'signing',\n",
       " 'somthing',\n",
       " 'static',\n",
       " 'summer',\n",
       " 'terrible',\n",
       " 'took',\n",
       " 'uefanationasleague',\n",
       " 'valid',\n",
       " 'wc',\n",
       " 'wise',\n",
       " 'x98if',\n",
       " 'xa9lix']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect.get_feature_names()[::100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5196"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vectorized=vect.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=10000)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model=LogisticRegression(max_iter=10000)\n",
    "model.fit(X_train_vectorized,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_vectorized=vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5763888888888888"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_test_vectorized, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
